+++
title = "Locally Stationary Distributions: A Framework for Analyzing Slow-Mixing Markov Chains"
author = "Sidhanth Mohanty (UC Berkeley)"
author_link = "https://sidhanthm.com/"
author_image = "assets/authorImages/sidhanthMohanty.png"
date = "2024-06-14T21:00:00+05:30"
date_end = "2024-06-14T22:00:00+05:30"
location = "YouTube Video Link"
location_link = "https://www.youtube.com/watch?v=LjVL1ki6KAw"
notes = "We are grateful to the <a href = "https://www.accel.com/people/shekhar-kirani" target= "_blank">Shekhar Kirani</a> family for generously supporting this seminar series."
+++

<b>Abstract:</b>
A common algorithmic task is to sample from some probability distribution of choice D. The most popular algorithm for
such tasks is to run a Markov chain with stationary distribution D, and when the Markov chain mixes rapidly, it does
indeed produce samples from D.
But what if the Markov chain does not mix fast? It is empirically observed that sometimes the output produced by the
Markov chain is nevertheless still a "good" solution for the downstream applications of sampling, even though it's not
faithfully sampling from the correct distribution.
For example, it appears to find planted cuts in random graphs, or planted solutions in random CSPs, despite the Markov
chain having bottlenecks to mixing.
In this talk, we will see some generic methods to analyze the structure of distributions that non-mixing Markov chains
sample from, along with some applications.
<br><br>
Based on joint work with Kuikui Liu, Prasad Raghavendra, Amit Rajaraman and David X Wu. https://arxiv.org/abs/2405.20849
<br><br>
<b>Abstract:</b>
<br>
Sidhanth is generally interested in algorithms and complexity in the average-case, and spectral graph theory. He is
currently a postdoctoral researcher at MIT, hosted by Sam Hopkins. Earlier, he got his PhD from UC Berkeley where he was
advised by Prasad Raghavendra.

