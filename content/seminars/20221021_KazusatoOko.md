+++
title = "Spectral sparsification of directed hypergraphs by spanner’s counterpart"
author = "Kazusato Oko (University of Tokyo)"
author_link = "#"
author_image = "assets/authorImages/kazusatoOko.jpg"
date = "2022-10-21T11:00:00+05:30"
date_end = "2022-10-21T12:00:00+05:30"
location = "Microsoft Teams Meeting"
location_link = "https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZGE3NDg5NzktMWQ0Zi00MzFmLTg5OTgtMTMyYWM4MWQyYjI2%40thread.v2/0?context=%7b%22Tid%22%3a%226f15cd97-f6a7-41e3-b2c5-ad4193976476%22%2c%22Oid%22%3a%227c84465e-c38b-4d7a-9a9d-ff0dfa3638b3%22%7d"
notes = "Jointly organized by <a href = "https://www.microsoft.com/en-us/research/lab/microsoft-research-india/" target= "_blank">Microsoft Research Lab - India</a> and <a href='https://www.csa.iisc.ac.in/theoretical-computer-science/' target= "_blank">Theoretical Computer Science @ IISc</a>"
+++

<b>Abstract:</b>
Spectral graph sparsification is the problem of finding a sparse graph that approximates the spectrum of a
given graph, and has contributed to speeding up various graph-based algorithms,  including linear system solvers
and GNNs. This notion has recently been extended to hypergraphs. For undirected hypergraphs, Kapralov et al.
(FOCS 2021) gave a spectral sparsifier of nearly linear size regarding the number of vertices.
<br><br>
In this talk, we introduce an algorithm for sparsification of directed hypergraphs, which produces a spectral
sparsifier of nearly quadratic size. This bound is optimal up to log factors. Our analysis is based on a
chaining-type argument by Kapralov et al. (FOCS 2021), together with a new combinatorial observation. The
algorithm is simple and can be seen as an extension of spanner-based graph sparsification algorithms. I also mention
how our framework is effective for various other settings of undirected hypergraph sparsification.
<br><br>
This is a joint work with Shinsaku Sakaue and Shin-ichi Tanigawa (University of Tokyo).
<br><br>
Speaker Bio:<br>
Kazusato Oko is currently a master’s course student in the Department of Mathematical Informatics at the
University of Tokyo. He has been advised by Taiji Suzuki. He also belongs to the deep learning theory team at the
RIKEN AIP as a research part-timer. He received his B.E. and Dean’s Award from the University of Tokyo in 2022,
supervised by Shin-ichi Tanigawa. His research interests include stochastic optimization, generalization of
neural networks, and analysis of discrete structures.
