+++
title = "Uncertainty Quantification for Large Language Models"
author = "Shubhendu Trivedi (MIT)"
author_link = "https://shubhendu-trivedi.org/"
author_image = "assets/authorImages/ShubhenduTrivedi.jpg"
date = "2024-11-04T16:00:00+05:30"
date_end = "2024-11-04T17:00:00+05:30"
location = "Online talk on Microsoft Teams"
location_link = "https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZGE3NDg5NzktMWQ0Zi00MzFmLTg5OTgtMTMyYWM4MWQyYjI2%40thread.v2/0?context=%7b%22Tid%22%3a%226f15cd97-f6a7-41e3-b2c5-ad4193976476%22%2c%22Oid%22%3a%227c84465e-c38b-4d7a-9a9d-ff0dfa3638b3%22%7d"
notes = "We are grateful to the <a href = "https://www.accel.com/people/shekhar-kirani" target= "_blank">Shekhar Kirani</a> family and the <a href = "https://www.csa.iisc.ac.in/cfe-walmart/" target= "_blank">Walmart Center for Tech Excellence</a> for generously supporting this seminar series."
+++

<b>Abstract:</b>
The rise of large language models (LLMs) has significantly advanced the state-of-the-art across a range of natural 
language generation tasks. However, deploying LLM-based compound systems for specific applications remains a 
challenging endeavor. For such systems to be applied reliably, we need accurate measures of uncertainty and confidence 
of LLM outputs. Here, uncertainty denotes the "dispersion" of possible predictions for a given input, while confidence 
pertains to the reliability of a particular input-generation pair. This talk will first define these basic notions and 
introduce simple baselines for confidence scoring and uncertainty quantification, and then discuss recent developments 
in the field, including fine-tuning techniques and conformal prediction methods.
