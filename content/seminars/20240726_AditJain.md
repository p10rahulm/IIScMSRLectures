+++
title = "Controlling Distributed Optimization for Robustness"
author = "Adit Jain (Cornell University)"
author_link = "https://aditj.github.io/"
author_image = "assets/authorImages/aditJain.png"
date = "2024-07-26T11:00:00+05:30"
date_end = "2024-07-26T12:00:00+05:30"
location = "YouTube Video Link"
location_link = "https://www.youtube.com/watch?v=cAlyi47lUG0"
notes = "We are grateful to the <a href = "https://www.accel.com/people/shekhar-kirani" target= "_blank">Shekhar Kirani</a> family and the <a href = "https://www.csa.iisc.ac.in/cfe-walmart/" target= "_blank">Walmart Center for Tech Excellence</a> for generously supporting this seminar series."
+++

<b>Abstract:</b>
Distributed optimization is used extensively in areas like pricing optimization and federated learning. In a 
centralized distributed optimization setting, when the distributed setup (oracle) is stochastic, it becomes 
important to ensure that optimization happens in a robust fashion, for e.g. when the oracle is in a 'good' state. 
We model the problem of dynamically learning from a stochastic oracle as a Markov decision process (MDP), and control 
the stochastic gradient descent performed by the learner. Under structural assumptions on the cost and transition 
matrix, we show that the optimal policy of the MDP has a threshold structure. Exploiting the structural results, a 
stochastic approximation algorithm is proposed to efficiently search for the optimal policy. The framework and 
structural results are extended to multiple central learners by formulating a switching control game. We numerically 
show the efficacy of our proposed methods in performing covert optimization and ensuring group fairness in federated 
learning.