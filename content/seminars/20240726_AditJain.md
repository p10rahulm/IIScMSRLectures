+++
title = "Controlling Distributed Optimization for Robustness"
author = "Adit Jain (Cornell University)"
author_link = "https://aditj.github.io/"
author_image = "assets/authorImages/aditJain.png"
date = "2024-07-26T11:00:00+05:30"
date_end = "2024-07-26T12:00:00+05:30"
location = "Offline talk at CSA 112, IISc Bangalore"
location_link = "https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZGE3NDg5NzktMWQ0Zi00MzFmLTg5OTgtMTMyYWM4MWQyYjI2%40thread.v2/0?context=%7b%22Tid%22%3a%226f15cd97-f6a7-41e3-b2c5-ad4193976476%22%2c%22Oid%22%3a%227c84465e-c38b-4d7a-9a9d-ff0dfa3638b3%22%7d"
notes = "We are grateful to the <a href = "https://www.accel.com/people/shekhar-kirani" target= "_blank">Shekhar Kirani</a> family for generously supporting this seminar series."
+++

<b>Abstract:</b>
Distributed optimization is used extensively in areas like pricing optimization and federated learning. In a 
centralized distributed optimization setting, when the distributed setup (oracle) is stochastic, it becomes 
important to ensure that optimization happens in a robust fashion, for e.g. when the oracle is in a 'good' state. 
We model the problem of dynamically learning from a stochastic oracle as a Markov decision process (MDP), and control 
the stochastic gradient descent performed by the learner. Under structural assumptions on the cost and transition 
matrix, we show that the optimal policy of the MDP has a threshold structure. Exploiting the structural results, a 
stochastic approximation algorithm is proposed to efficiently search for the optimal policy. The framework and 
structural results are extended to multiple central learners by formulating a switching control game. We numerically 
show the efficacy of our proposed methods in performing covert optimization and ensuring group fairness in federated 
learning.